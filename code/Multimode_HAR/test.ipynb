{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "\n",
    "source_domain_list = ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10',\n",
    "                      '11', '12', '13', '14', '15', '16', '17', '18', '19', '20',\n",
    "                      '21', '22', '23', '24', '25', '26', '27', '28', '29', '30']\n",
    "\n",
    "def get_k_fold_data(k, i, X):\n",
    "    \"\"\"\n",
    "    返回第i折训练的训练集的志愿者编号和测试集志愿者编号,X_train_user为训练数据,X_test_user为验证数据\n",
    "    k: k折交叉验证------->\n",
    "    i: 第i折作测试集\n",
    "    X: source_domain_list\n",
    "    \"\"\"\n",
    "    assert k > 1 and i < k\n",
    "    fold_size = len(X) // k  # 6 每份的个数:数据总条数/折数（组数）\n",
    "    X_train = []\n",
    "    for j in range(k):\n",
    "        idx = slice(j * fold_size, (j + 1) * fold_size)  #slice(start,end,step)切片函数\n",
    "        # idx 为每组 valid\n",
    "        X_part = X[idx]\n",
    "        if j == i: ###第i折作valid\n",
    "            X_test = X_part\n",
    "        elif X_train is None:\n",
    "            X_train = X_part\n",
    "        else:\n",
    "            X_train = np.concatenate([X_train, X_part])\n",
    "\n",
    "    return X_train, X_test\n",
    "\n",
    "def k_fold(k, X_train, y_train, num_epochs=3,learning_rate=0.001, weight_decay=0.1, batch_size=5):\n",
    "    train_loss_sum, valid_loss_sum = 0, 0\n",
    "    train_acc_sum ,valid_acc_sum = 0,0\n",
    "\n",
    "    for i in range(k):\n",
    "        data = get_k_fold_data(k, i, X_train, y_train) # 获取k折交叉验证的训练和验证数据\n",
    "        # net =  Net()  ### 实例化模型\n",
    "        # train_ls, valid_ls = train(net, *data, num_epochs, learning_rate,\\\n",
    "        #                            weight_decay, batch_size)\n",
    "        print('*'*25,'第',i+1,'折','*'*25)\n",
    "        print('train_loss:%.6f'%train_ls[-1][0],'train_acc:%.4f\\n'%valid_ls[-1][1],\\\n",
    "              'valid loss:%.6f'%valid_ls[-1][0],'valid_acc:%.4f'%valid_ls[-1][1])\n",
    "        # train_loss_sum += train_ls[-1][0]\n",
    "        # valid_loss_sum += valid_ls[-1][0]\n",
    "        # train_acc_sum += train_ls[-1][1]\n",
    "        # valid_acc_sum += valid_ls[-1][1]\n",
    "    print('#'*10,'最终k折交叉验证结果','#'*10)\n",
    "    print('train_loss_sum:%.4f'%(train_loss_sum/k),'train_acc_sum:%.4f\\n'%(train_acc_sum/k),\\\n",
    "          'valid_loss_sum:%.4f'%(valid_loss_sum/k),'valid_acc_sum:%.4f'%(valid_acc_sum/k))\n",
    "\n",
    "train_domain, test_domain = get_k_fold_data(30,0,source_domain_list)\n",
    "print(train_domain)\n",
    "print(test_domain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_device_data(fold_iter):\n",
    "    assert fold_iter < 81\n",
    "    device = ['insole_head', 'insole_arm_l', 'insole_arm_r', 'insole_wrist_l', 'insole_wrist_r',\n",
    "                'insole_chest', 'insole_knee_l', 'insole_knee_r', 'insole_pocket']\n",
    "    train_index = int(fold_iter / 9)\n",
    "    test_index = fold_iter % 9\n",
    "\n",
    "    return device[train_index], device[test_index]\n",
    "\n",
    "train_device, test_device = get_device_data(0)\n",
    "print(train_device)\n",
    "print(test_device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**活动分布以及混淆矩阵**"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lbls = [\"Walking\", \"Stairs-Up\", \"Stairs-Down\", \"Sitting\", \"Standing\", \"Lying\"]\n",
    "def plot_confusion_matrix(cm):\n",
    "    fig, ax = plt.subplots(figsize = (12,8))\n",
    "    ax.grid(False)\n",
    "    im = ax.imshow(cm, interpolation = 'nearest', cmap = plt.cm.Oranges)\n",
    "    ax.figure.colorbar(im, ax = ax)\n",
    "    ax.set_xlabel('Predicted label', fontsize=12)\n",
    "    ax.set_ylabel('True label', fontsize=12)\n",
    "    ax.set_xticklabels([''] + lbls)\n",
    "    ax.set_yticklabels([''] + lbls)\n",
    "    plt.xticks(rotation=90)\n",
    "    thresh = cm.max() / 2\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, int(cm[i,j]), ha = \"center\", va = \"center\", color = \"white\" if cm[i,j]> thresh else \"black\", fontsize=16)\n",
    "            fig.tight_layout()\n",
    "\n",
    "cm = confusion_matrix(Y_test, prediction)\n",
    "plot_confusion_matrix(cm)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**特征工程**"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "train_x = np.load('/home/intelligence/Robin/Dataset/MM_train_x.npy')\n",
    "train_x.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mean_feature_dim = np.array([])\n",
    "std_feature_dim = np.array([])\n",
    "range_feature_dim = np.array([])\n",
    "var_feature_dim = np.array([])\n",
    "for i in range(len(train_x)):\n",
    "    mean_win = np.mean(train_x[i], axis=0).reshape(1,-1)\n",
    "    std_win = np.std(train_x[i], axis=0).reshape(1,-1)\n",
    "    variance = np.var(train_x[i], axis=0).reshape(1,-1)\n",
    "\n",
    "    data_max = np.max(train_x[i], axis=0).reshape(1,-1)\n",
    "    data_min = np.min(train_x[i], axis=0).reshape(1,-1)\n",
    "    range_win = (data_max - data_min)\n",
    "\n",
    "    mean_feature_dim = np.concatenate((mean_feature_dim, mean_win), axis=0) if mean_feature_dim.size else mean_win  # 平均值\n",
    "    std_feature_dim = np.concatenate((std_feature_dim, std_win), axis=0) if std_feature_dim.size else std_win  # 标准差\n",
    "    range_feature_dim = np.concatenate((range_feature_dim, range_win), axis=0) if range_feature_dim.size else range_win  # 范围\n",
    "    var_feature_dim = np.concatenate((var_feature_dim, variance), axis=0) if var_feature_dim.size else variance  # 方差"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "# 提取偏度和峰度\n",
    "Skewness_feature_dim = np.array([])\n",
    "kurtosis_feature_dim = np.array([])\n",
    "for i in range(len(train_x)):\n",
    "    Skewness = stats.skew(train_x[i]).reshape(1,-1)\n",
    "    Kurtosis = stats.kurtosis(train_x[i]).reshape(1,-1)\n",
    "    Skewness_feature_dim = np.concatenate((Skewness_feature_dim, Skewness), axis=0) if Skewness_feature_dim.size else Skewness\n",
    "    kurtosis_feature_dim = np.concatenate((kurtosis_feature_dim, Kurtosis), axis=0) if kurtosis_feature_dim.size else Kurtosis"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**TRASEND论文中有进行傅里叶变换**"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 压力时间积分\n",
    "# PTI_feature_dim = np.array([])\n",
    "#\n",
    "# for i in range(len(train_x)):\n",
    "#     win_sum = np.zeros(len(train_x[0][0]))\n",
    "#     for j in range(len(train_x[0])):\n",
    "#         PTI = train_x[i][j] * (j/350)\n",
    "#         win_sum += PTI\n",
    "#     win_sum = win_sum.reshape(1,-1)\n",
    "#     PTI_feature_dim = np.concatenate((PTI_feature_dim, win_sum), axis=0) if PTI_feature_dim.size else win_sum"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 提取频域energe特征\n",
    "# DFR_feature_dim = np.array([])\n",
    "# for i in range(len(train_x)):\n",
    "#     data_fft  = np.fft.fft(train_x[i], axis=0)\n",
    "#     m, N = data_fft.shape\n",
    "#     mag = np.abs(data_fft)\n",
    "#     DFR = np.sum((mag[:m, :] ** 2)/m, axis=0).reshape(1,-1)\n",
    "#     DFR_feature_dim = np.concatenate((DFR_feature_dim, DFR), axis=0) if DFR_feature_dim.size else DFR"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 提取entropy\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "feature_train_x = np.hstack((mean_feature_dim, std_feature_dim, var_feature_dim, range_feature_dim, Skewness_feature_dim, kurtosis_feature_dim))\n",
    "np.save('/home/intelligence/Robin/Dataset/feature_MM_train_x.npy', feature_train_x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**特征选择**"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 导入数据集\n",
    "df = pd.read_csv(\"/home/intelligence/Robin/Dataset/diabetes.csv\")\n",
    "data=df.iloc[:,:8]\n",
    "target=df.iloc[:,-1]\n",
    "\n",
    "# 切分训练集和测试集\n",
    "train_x, test_x, train_y, test_y = train_test_split(data,target,test_size=0.2,random_state=7)\n",
    "\n",
    "# xgboost模型初始化设置\n",
    "dtrain=xgb.DMatrix(train_x,label=train_y)\n",
    "dtest=xgb.DMatrix(test_x)\n",
    "watchlist = [(dtrain,'train')]\n",
    "\n",
    "# booster:\n",
    "params={'booster':'gbtree',\n",
    "        'objective': 'binary:logistic',\n",
    "        'eval_metric': 'auc',\n",
    "        'max_depth':5,\n",
    "        'lambda':10,\n",
    "        'subsample':0.75,\n",
    "        'colsample_bytree':0.75,\n",
    "        'min_child_weight':2,\n",
    "        'eta': 0.025,\n",
    "        'seed':0,\n",
    "        'nthread':8,\n",
    "        'gamma':0.15,\n",
    "        'learning_rate' : 0.01}\n",
    "\n",
    "# 建模与预测：50棵树\n",
    "bst=xgb.train(params,dtrain,num_boost_round=50,evals=watchlist)\n",
    "ypred=bst.predict(dtest)\n",
    "\n",
    "# 设置阈值、评价指标\n",
    "y_pred = (ypred >= 0.5)*1\n",
    "print ('Precesion: %.4f' %metrics.precision_score(test_y,y_pred))\n",
    "print ('Recall: %.4f' % metrics.recall_score(test_y,y_pred))\n",
    "print ('F1-score: %.4f' %metrics.f1_score(test_y,y_pred))\n",
    "print ('Accuracy: %.4f' % metrics.accuracy_score(test_y,y_pred))\n",
    "print ('AUC: %.4f' % metrics.roc_auc_score(test_y,ypred))\n",
    "\n",
    "ypred = bst.predict(dtest)\n",
    "print(\"测试集每个样本的得分\\n\",ypred)\n",
    "ypred_leaf = bst.predict(dtest, pred_leaf=True)\n",
    "print(\"测试集每棵树所属的节点数\\n\",ypred_leaf)\n",
    "ypred_contribs = bst.predict(dtest, pred_contribs=True)\n",
    "print(\"特征的重要性\\n\",ypred_contribs )\n",
    "\n",
    "xgb.plot_importance(bst,height=0.8,title='影响糖尿病的重要特征', ylabel='特征')\n",
    "plt.rc('font', family='Arial Unicode MS', size=14)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**DeepSense**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class BasicConv(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes, kernel_size, stride=1, padding=(1, 0), dilation=1, groups=1, relu=True, bn=True, bias=False):\n",
    "        super(BasicConv, self).__init__()\n",
    "        self.out_channels = out_planes\n",
    "        self.conv = nn.Conv2d(in_planes, out_planes, kernel_size=kernel_size, stride=stride, padding=padding, dilation=dilation, groups=groups, bias=bias)\n",
    "        self.bn = nn.BatchNorm2d(out_planes) if bn else None\n",
    "        self.relu = nn.ReLU() if relu else None\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        if self.bn is not None:\n",
    "            x = self.bn(x)\n",
    "        if self.relu is not None:\n",
    "            x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ZPool(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return torch.cat((torch.max(x, 1)[0].unsqueeze(1), torch.mean(x, 1).unsqueeze(1)), dim=1)\n",
    "\n",
    "\n",
    "class AttentionGate(nn.Module):\n",
    "    def __init__(self, temperature):\n",
    "        super(AttentionGate, self).__init__()\n",
    "        kernel_size = (5, 1)\n",
    "        self.temperature = temperature\n",
    "        self.compress = ZPool()\n",
    "        # self.conv = BasicConv(2, 1, kernel_size, stride=1, padding=(kernel_size-1) // 2, relu=False)\n",
    "        self.conv = BasicConv(2, 1, kernel_size, stride=1, padding=(2, 0), relu=False)\n",
    "\n",
    "    def updata_temperature(self):\n",
    "        if self.temperature != 1:\n",
    "            self.temperature -= 3\n",
    "            print('Change temperature to:', str(self.temperature))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(x.shape, 'ty1')\n",
    "        x_compress = self.compress(x)\n",
    "        # print(x_compress.shape, 'Z_pooling')\n",
    "        x_out = self.conv(x_compress)\n",
    "        # print(x_out.shape, 'Conv+BN+RelU')\n",
    "        # scale = torch.softmax(x_out/self.temperature, 1)\n",
    "        scale = torch.sigmoid(x_out)\n",
    "        # print((x*scale).shape, 'ty4')\n",
    "        return x * scale\n",
    "\n",
    "\n",
    "class TripletAttention(nn.Module):\n",
    "    def __init__(self, no_spatial=False, temperature=34):\n",
    "        super(TripletAttention, self).__init__()\n",
    "\n",
    "        self.cw = AttentionGate(temperature)\n",
    "        self.hc = AttentionGate(temperature)\n",
    "        self.no_spatial = no_spatial\n",
    "\n",
    "        self.w1 = torch.nn.Parameter(torch.FloatTensor(1), requires_grad=True)\n",
    "        self.w2 = torch.nn.Parameter(torch.FloatTensor(1), requires_grad=True)\n",
    "        self.w3 = torch.nn.Parameter(torch.FloatTensor(1), requires_grad=True)\n",
    "\n",
    "        # initialization\n",
    "        # self.w1 = torch.nn.init.normal_(self.w1)\n",
    "        # self.w2 = torch.nn.init.normal_(self.w2)\n",
    "        # self.w3 = torch.nn.init.normal_(self.w3)\n",
    "        self.w1.data.fill_(1/3)\n",
    "        self.w2.data.fill_(1/3)\n",
    "        self.w3.data.fill_(1/3)\n",
    "\n",
    "        if not no_spatial:\n",
    "            self.hw = AttentionGate(temperature)\n",
    "\n",
    "    def update_temperature(self):\n",
    "        self.cw.updata_temperature()\n",
    "        self.hc.updata_temperature()\n",
    "        self.hw.updata_temperature()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)\n",
    "        x_perm1 = x.permute(0, 2, 1, 3).contiguous()\n",
    "        x_out1 = self.cw(x_perm1)\n",
    "        # print(x_out1.shape, 'ty44')\n",
    "        x_out11 = x_out1.permute(0, 2, 1, 3).contiguous()\n",
    "        x_perm2 = x.permute(0, 3, 2, 1).contiguous()\n",
    "        x_out2 = self.hc(x_perm2)\n",
    "        x_out21 = x_out2.permute(0, 3, 2, 1).contiguous()\n",
    "        if not self.no_spatial:\n",
    "            x_out = self.hw(x)\n",
    "            # print(x_out.shape, 'ty55')\n",
    "            # x_out = x_out11\n",
    "            # x_out = 1/3 * (x_out + x_out11 + x_out21)\n",
    "            # x_out = 4 * x_out + 5 * x_out11 + 6 * x_out21\n",
    "            x_out = self.w1 * x_out + self.w2 * x_out11 + self.w3 * x_out21\n",
    "            # print(self.w1, self.w2, self.w3, 'w1,w2,w3')\n",
    "            # print(x_out.shape, 'ty22')\n",
    "        else:\n",
    "            x_out = self.w1 * x_out11 + self.w2 * x_out21\n",
    "        # return x_out, self.w1, self.w2, self.w3\n",
    "        return x_out\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T06:59:36.286632900Z",
     "start_time": "2024-01-06T06:59:36.230130300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 1, 300, 25])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(128, 300, 25)\n",
    "model = TripletAttention()\n",
    "x = x.to('cuda:0')\n",
    "model.to('cuda')\n",
    "out = model(x)\n",
    "# print(model)\n",
    "print(out.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T06:59:38.284659600Z",
     "start_time": "2024-01-06T06:59:38.238643100Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "60400120780fc64f050dbab3aaab66623a9f9ce33d1c80af1ed659c17c82ee60"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
