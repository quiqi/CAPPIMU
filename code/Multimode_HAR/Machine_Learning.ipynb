{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "**统计特征提取**"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x shape:(11924, 300, 9)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "train_x = np.load('/home/intelligence/Robin/Dataset/save_raw_data/pocket_test_win_x.npy')\n",
    "print(f'train_x shape:{train_x.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [],
   "source": [
    "mean_feature_dim = np.array([])\n",
    "std_feature_dim = np.array([])\n",
    "range_feature_dim = np.array([])\n",
    "var_feature_dim = np.array([])\n",
    "for i in range(len(train_x)):\n",
    "    mean_win = np.mean(train_x[i], axis=0).reshape(1,-1)\n",
    "    std_win = np.std(train_x[i], axis=0).reshape(1,-1)\n",
    "    variance = np.var(train_x[i], axis=0).reshape(1,-1)\n",
    "\n",
    "    data_max = np.max(train_x[i], axis=0).reshape(1,-1)\n",
    "    data_min = np.min(train_x[i], axis=0).reshape(1,-1)\n",
    "    range_win = (data_max - data_min)\n",
    "\n",
    "    mean_feature_dim = np.concatenate((mean_feature_dim, mean_win), axis=0) if mean_feature_dim.size else mean_win  # 平均值\n",
    "    std_feature_dim = np.concatenate((std_feature_dim, std_win), axis=0) if std_feature_dim.size else std_win  # 标准差\n",
    "    range_feature_dim = np.concatenate((range_feature_dim, range_win), axis=0) if range_feature_dim.size else range_win  # 范围\n",
    "    var_feature_dim = np.concatenate((var_feature_dim, variance), axis=0) if var_feature_dim.size else variance  # 方差\n",
    "\n",
    "from scipy import stats\n",
    "# 提取偏度和峰度\n",
    "Skewness_feature_dim = np.array([])\n",
    "kurtosis_feature_dim = np.array([])\n",
    "for i in range(len(train_x)):\n",
    "    Skewness = stats.skew(train_x[i]).reshape(1,-1)\n",
    "    Kurtosis = stats.kurtosis(train_x[i]).reshape(1,-1)\n",
    "    Skewness_feature_dim = np.concatenate((Skewness_feature_dim, Skewness), axis=0) if Skewness_feature_dim.size else Skewness\n",
    "    kurtosis_feature_dim = np.concatenate((kurtosis_feature_dim, Kurtosis), axis=0) if kurtosis_feature_dim.size else Kurtosis\n",
    "\n",
    "\n",
    "feature_train_x = np.hstack((mean_feature_dim, std_feature_dim, var_feature_dim, range_feature_dim, Skewness_feature_dim,kurtosis_feature_dim))\n",
    "np.save('/home/intelligence/Robin/Dataset/feature_data/feature_pocket_test_x.npy', feature_train_x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**SVM/RB/KNN**"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train: (27820, 54), x_test: (11924, 54), y_train: (27820,), y_test: (11924,), \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "train_x = np.load('/home/intelligence/Robin/Dataset/feature_data/feature_pocket_train_x.npy',allow_pickle=True)\n",
    "train_y = np.load('/home/intelligence/Robin/Dataset/feature_data/pocket_train_win_y.npy',allow_pickle=True)\n",
    "test_x = np.load('/home/intelligence/Robin/Dataset/feature_data/feature_pocket_test_x.npy',allow_pickle=True)\n",
    "test_y = np.load('/home/intelligence/Robin/Dataset/feature_data/pocket_test_win_y.npy',allow_pickle=True)\n",
    "\n",
    "print(\"x_train: {}, x_test: {}, y_train: {}, y_test: {}, \".format(train_x.shape, test_x.shape,train_y.shape,test_y.shape))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Best Parameters: {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "F1 Score: 78.56424018785644 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "classifier = svm.SVC()\n",
    "parameters = [{'kernel': ['rbf'], 'gamma': [0.01, 0.001, 0.0001, 0.00001], 'C': [1, 10, 100, 1000]}]\n",
    "model = GridSearchCV(classifier,parameters,n_jobs=-1,cv=4,verbose=1)\n",
    "model.fit(train_x,train_y)\n",
    "\n",
    "pred_y = model.predict(test_x)\n",
    "metrics = f1_score(test_y, pred_y, average='micro')\n",
    "print('Best Parameters: '+ str(model.best_params_))\n",
    "print('F1 Score: '+ str(metrics * 100) + ' %')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 18 candidates, totalling 72 fits\n",
      "Best Parameters: {'max_depth': 9, 'max_features': 'auto', 'n_estimators': 1000}\n",
      "F1 Score: 82.53102985575312 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "classifier = RandomForestClassifier()\n",
    "parameters = {'n_estimators': [10, 100, 1000], 'max_depth': [3, 6, 9], 'max_features' : ['auto', 'log2']}\n",
    "model=GridSearchCV(classifier,parameters,n_jobs=-1,cv=4,scoring='f1_micro',verbose=4)\n",
    "model.fit(train_x,train_y)\n",
    "\n",
    "pred_y = model.predict(test_x)\n",
    "metrics = f1_score(test_y, pred_y, average='micro')\n",
    "print('Best Parameters: '+ str(model.best_params_))\n",
    "print('F1 Score: '+ str(metrics * 100) + ' %')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/4] END max_depth=3, max_features=auto, n_estimators=1000;, score=0.563 total time=  40.3s\n",
      "[CV 2/4] END max_depth=3, max_features=auto, n_estimators=1000;, score=0.539 total time=  40.4s\n",
      "[CV 3/4] END max_depth=3, max_features=auto, n_estimators=1000;, score=0.545 total time=  40.9s\n",
      "[CV 1/4] END max_depth=3, max_features=auto, n_estimators=1000;, score=0.557 total time=  41.0s\n",
      "Optimal No. Of Neighbors:1\n",
      "F1 Score: 68.82757463938276 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#Finding the optimal model by varying the no. of neighbors\n",
    "scores = []\n",
    "for i in range(1, 30):\n",
    "    knn = KNeighborsClassifier(n_neighbors = i, n_jobs = -1)\n",
    "    knn.fit(train_x, train_y)\n",
    "    pred_y = knn.predict(test_x)\n",
    "    metrics = f1_score(test_y, pred_y, average='micro')\n",
    "    scores.append(metrics)\n",
    "\n",
    "scores = np.array(scores)\n",
    "print('Optimal No. Of Neighbors:{}'.format(scores.argmax()+1))\n",
    "print('F1 Score: '+ str(scores.max() * 100) + ' %')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}